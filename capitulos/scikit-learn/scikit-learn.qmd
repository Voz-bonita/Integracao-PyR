---
title: "Machine Learning com scikit-learn no R"
author: "Pedro Lima"
format:
  html:
    toc: true
    self-contained: true
knitr:
  opts_chunk:
    echo: true
    warnings: false
editor: visual
---

O [scikit-learn](https://scikit-learn.org/stable/getting_started.html) é uma biblioteca para Python muito popular por conter um vasto conjunto de algoritmos para processamento de dados e construção de modelos de machine learning implementados de maneira consistente, eficiente e de fácil utilização. Conta ainda com uma [documentação](https://scikit-learn.org/stable/user_guide.html) muito bem organizada, clara e repleta de exemplos e tutoriais.

## O que você pode fazer com o scikit-learn

-   **Pré-processamento**
    -   Seleção, transformação e extração de variáveis;
    -   Codificação de dados categorizados;
    -   Redução de dimensionalidade (PCA, FA etc.);
    -   Imputação de missing values;
    -   Manipulação de dados em texto.
-   **Modelos**
    -   **Regressão:** linear, LASSO, ridge etc;

    -   **Classificação:** regressão logística, árvore de decisão, support vector machine, análise de discriminante etc;

    -   **Clustering:** K-means, misturas gaussianas etc.
-   **Avaliação e seleção de modelos**
    -   Validação cruzada

## Integrando o scikit-learn ao R

### Preparação

O primeiro passo é carregar o pacote `reticulate`. Em seguida, definimos a instalação Python a ser usada; nesse caso, o ambiente "base" do Anaconda.

```{r}
library(reticulate)
use_condaenv("base")
# use_python("C:/Users/pedro/anaconda3")
```

> O [Anaconda](https://www.anaconda.com) é uma distribuição Python que permite manter múltiplas versões do interpretador, cada uma com seus próprios pacotes. Seu ambiente base vem por padrão com diversos pacotes para data science, incluindo o scikit-learn.

Caso o pacote scikit-learn não esteja instalada no Python, podemos usar o reticulate para fazer isso.

```{r}
# conda_install("base", "sklearn")
# py_install("sklearn")
```

### Exemplo

A própria biblioteca scikit carrega alguns conjuntos de dados e métodos de geração de dados simulados para quem quiser treinar ou fazer testes.

Para exemplificar o uso do sklearn no R, utilizaremos o conjunto *breast cancer winconsin*.

```{python}
from sklearn.datasets import load_breast_cancer

X, y = load_breast_cancer(return_X_y=True)
```

-   `X`: data frame/matriz cujas colunas são variáveis preditoras

-   `y`: vetor da variável resposta

#### Divisão em treino e teste

No contexto de machine learning, é uma prática rotineira separar os dados em treino e teste, geralmente, numa proporção de 4 para 1. Isso ajuda a avaliar a capacidade de generalização do modelo para além dos dados de ajuste, e pode ser feito do seguinte modo no sklearn:

```{python}
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X , y, train_size=0.8, random_state=42)
```

> O parâmetro `random_state` fixa a semente de geração de números aleatórios para a reprodução de resultados.

#### Pipeline

Um pipeline lembra o pipe `%>%` do R, e descreve uma sequência de transformações seguida de um modelo. É muito útil para unificar e simplificar os processos de pré-processamento, estimação e ajuste de hiperparâmetros, bem como para fazer previsões.

O modelo de classificação consistirá de uma padronização de média e variância das variáveis seguida de uma decomposição em componentes principais e por fim um *support vector classifier*.

```{python}
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import LinearSVC

model = Pipeline([
  ("scaler", StandardScaler()),
  ("pca", PCA(n_components=5)),
  ("svc", LinearSVC(C=8.71))
])
```

> Tanto o parâmetro `n_components` do PCA quanto o `C` do LinearSVC são hiperparâmetros desse modelo `model`, e podem ser ajustados utilizando os métodos do `GridSearchCV()`, `RandomSearchCV()` etc do módulo `model_selection` sobre o pipeline.

Segue o ajuste do modelo utilizando os dados de **treino**.

```{python}
model.fit(X_train, y_train)
```

> **(Vazamento de dados)**. Veja que o pipeline ajuda a reforçar o uso dos dados de **treino** em todas as etapas de construção do modelo.

Agora, a verificação da acurácia no conjunto de **teste**.

```{python}
from sklearn.metrics import accuracy_score

y_pred = model.predict(X_test)
print("Precisão:", accuracy_score(y_test, y_pred))
```

#### Exportando os resultados para o R

Podemos enfim trazer alguma parte de interesse do resultado para o R, por exemplo, os coeficientes do modelo armazenados na variável `svc_coefs`.

```{python}
svc_coefs = model["svc"].coef_
```

```{r}
py$svc_coefs
```

## Materiais

1.  Para mais informações sobre a biblioteca scikit-learn, veja a sua [página](https://scikit-learn.org/stable/getting_started.html) na web e [documentação](https://scikit-learn.org/stable/user_guide.html).
2.  [GÉRON, Aurelin (2019)](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow.
